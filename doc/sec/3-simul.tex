\section{Simulation}
In Kapitel \ref{sec-model} wurde folgendes Modell ausgewählt:
\begin{equation}
	soil.res = \vec{\beta} * (1,lmoi,temp15,smoi)^T
\end{equation}

\subsection{Vorgehensweise}
Die Daten wurden in 80\% zum Training und 20\% zum Testen aufgeteilt.
Anschließend wurde das "wahre" Modell um jeweils ein weiteres Feature erweitert.
Das erweiterte Modell $soil.res = \vec{\beta} * (1,lmoi,temp15,smoi,x)^T$ wurde mittels ANOVA mit dem "wahren" Modell verglichen.
In R berechnete die Funktion \lstinline|anova(realModel, nxtModel)$F[2]| den jeweiligen F-Wert.
Wichtig hierbei war, dass beide Modelle auf den selben Trainingsdaten erstellt wurden und es sich um \it{verschachtelte} Featuremengen handelte.
Die Partitionierung der Daten erfolgte sowohl mittels Kreuzvalidierung als auch mit einem Monte-Carlo-Ansatz.
Bei der 4-fachen Kreuzvalidierung wurden die Daten in vier möglichst gleich großen Partitionen aufgeteilt.
Eine Partition wurde zum Testen des Reproduktionsfehlers verwendet, die Anderen zum Training.
Beim Monte-Carlo-Ansatz wurden 100 mal zufällig 20\% der Daten zum Testen ausgewählt.
Dadurch kann die Wahrscheinlichkeit der Fehlentscheidungen im Bezug auf die Nullhypothese besser geschätzt werden.
Die Ermittlung des Reproduktionsfehlers $\widehat{SPSE}$ erfolgte mittels unabhängigen Testdaten.
Um zu überprüfen, ob sich das Modell überhaupt verbessert hat, wurde die Differenz $\Delta \widehat{SPSE}$ im Bezug auf das Ausgangsmodell berechnet.

\subsection{Auswertung}
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{fig/simul/simul-f.pdf}
	\includegraphics[width=\textwidth]{fig/simul/simul-spse.pdf}
	\caption{\bf{Beispiel einer Simulation.} 
		Das in Kapitel \ref{sec-model} erstellte "wahre" Modell wurde um jeweils ein Feature erweitert.
		Dargestellt ist der Fehler \bf{SPSE} und der zugehörige \bf{F-Wert} in Abhänigkeit von der gewählten zusätzlichen Variable in der ersten Runde der Kreuzvalidierung.
		Im Verlaufe der Variablenselektion wird das Modell mit dem höchsten F-Wert gewählt.
		Dies ist allerdings selten das Modell mit dem geringsten Fehler.
	}
	\label{fig-simul-f-spse}
\end{figure}
In Abbildung \ref{fig-simul-f-spse} sind die F-Werte und Fehler bei der Reproduktion von unabhängigen Testdaten gezeigt.
Im Rahmen des Variablenselektionsverfahrens wird jeweils das Feature zum Modell hinzugenommen, welches um den größten F-Wert verfügt.
Im diesem Falle wäre das $litter.d$.
Betrachtet man allerdings den erwarteten Reproduktionsfehler $\widehat{SPSE}$, so führt das Hinzunehmen der Variable $ph.soil5$ zum Modell mit minimalen Fehlern.
Hier ist der F-Wert aber um $\approx 3,5$ geringer.
Die Nullhypothese wird hier fälschlicherweise abgelehnt und stattdessen $litter.d$ zum Modell hinzugenommen.
Auch kann es vorkommen, dass eine Zufallsvariable überwiegend Rauschen beinhaltet und sich das Modell dann durch hinzufügen ebendieser Variable lediglich verschlechtert (Vgl. Abb. \ref{fig-simul-delta-spse})
\\
Nach der Monte-Carlo-Simulation war das Modell mit dem geringsten $\widehat{SPSE}$ stets das Modell mit den 9. höchsten F-Wert.
Während der 200 Simulationen verblieb der Wert unverändert.
\\
\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{fig/simul/kernel.pdf}
	\caption{\bf{Approximierte Dichtefunktionen der F-Werte.} 
		Gezeigt ist die Kerneldichtefunktion der F-Werte der Simulationen und die berechnete F-Dichtefunktion mit den Freiheitsgraden der ANOVA-Tabelle unter Berücksichtigung der Nullhypothese.
		Der Unterschied der beiden Funktionen deutet auf fehlerhafte F-tests hin.
	}
	\label{fig-simul-kernel}
\end{figure}

Unter der Nullhypothese (Erweitertes Modell ist nicht besser als das "wahre" Modell) ist die F-Statistik eine F-verteilte Zufallsvariable.
Die Dichtefunktion der Daten aus der Kreuzüberprüfung (approx. durch Kernel-Desity) ist nach Abb. \ref{fig-simul-kernel} mitunter stark abweichend.
Die Simulation möchte demnach das wahre Modell erweitern ($H_0$ wird abgelehnt).
Dies führt zu Overfitting, da das Modell bereits als wahr angenommen wurde und demnach keine weiteren Features hinzugefügt werden sollten.

\subsection{Diskussion}

\subsubsection{Mögliche Gründe}
Dies kann mehrere Gründe haben:
Gemessene Features müssen nicht zwangsläufig von der Bodenatmung statistisch abhängig sein.
Je geringer die Korrelation dieser beiden Zufallsvariablen, desto höher ist die Wahrscheinlichkeit, dass es sich nur um Rauschen handelt.
In diesem Fall sollte diese Variable nicht zum Modell hinzugefügt werden.
Zufälligerweise kann dies aber auch zu hohen F-Werten führen, welches zu fehlerhaften Entscheidungen bei den Hypothesentests führt.
Ferner fordert der F-Test normalverteilte Variablen.
Folgt eine Messgröße nicht dieser Verteilung, ist der Test nicht aussagekräftig.
Auch eine nicht repräsentative Stichprobe fälscht das Ergebnis.
Uns lagen lediglich 38 Observationen vor; dies könnte zu gering sein.
Eine fehlerhafte Datenerhebung führt auch zu verfälschten Ergebnissen.
Letztendlich kann der F-Test auch nur zufällig richtig sein.
Ein geringer p-Value schließt keine Fehlentscheidungen aus; sie werden lediglich unwahrscheinlicher.

\subsubsection{Auswirkungen der Fehlentscheidungen}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{fig/simul/delta-spse.pdf}
	\caption{\bf{Verbesserung der Modelle.} 
		Dargestellt ist die Differenz $\Delta \widehat{SPSE}$ aus dem „wahren“ und dem erweiterten Modell.
		Positive Werte deuten darauf hin, dass die hinzugefügte Variable dem Modell lediglich Rauschen beifügt.
	}
	\label{fig-simul-delta-spse}
\end{figure}
