\section{Einleitung}
\label{sec-intro}

\subsection{Bodenatmung als geophysikalischer Prozess}
Zur Berechnung von Klimamodellen stellt die Konzentration \ch{CO2} ein eminentes Feature dar.
In Landgebieten beeinflusst die Bodenatmung diesen Prozess am Meisten.
Insbesondere in den Humusschichten emittieren Mikroorganismen und andere Destruenten das Treibhausgas.
Im folgendem wird der Einfluss von Temperatur, Feuchtigkeit und Strukturvariablen wie z.B. die Dicke der Streuschicht oder Wurzelanteil auf die Bodenatmung evaluiert.

\subsection{Statistische Grundlagen}

\subsubsection{Fehlermaße}
SPSE ist der summierte quadratische Fehler zwischen Modellvorhersage und Messwert auf unabhängigen Testdaten:
\begin{equation}
	\widehat{SPSE} = \sum_{i=1}^n (y_i - \vec{\beta} * x_i^T )^2
\end{equation}
Das Modell wurde vorher mit anderen Trainingsdaten erstellt.
Die Testdaten sind statistisch unabhängig.

\subsubsection{Korrelation}
Unter \it{Korrelation} versteht man die „Wechselbeziehung“ zweier Zufallsgrößen.
Dieser Zusammenhang kann entweder \it{linear} (Korrelationskoeffizient nach Pearson) oder lediglich \it{monoton} sein.
Ist eine Korrelation nicht gegeben, so scheint die Zufallsgröße als ungeeigneter Prädiktor für die jeweils andere Variable.
Kausale Beziehungen erfordern Korrelation.
\\
Der \it{lineare, empirische Korrelationskoeffizient nach Person} zwischen den Variablen $X$ und $Y$ wird definiert durch:
\begin{equation}
	Kor_e(x,y) := \varrho_e(x,y) := r_{xy} := \frac{
		\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)
	}{
	\sqrt{
		\sum_{i=1}^n(x_i-\bar x)^2\cdot
		\sum_{i=1}^n(y_i-\bar y)^2
	}
	}
\end{equation}
mit den empirischen Mittelwert $\bar x$ aus $n$ Messwerten von $X$.
Möchte man lediglich ein \it{lineares} Modell erstellen, so ist die Pearson-Korrelation zu wählen.
\\
Eine allgemeinere Beschreibung der Korrelation ist die nach \it{Spearman}, welche auf Ranglisten beruht:\\
\begin{align}
	r_s &= \frac{\sum_{i}(rg(x_i)-\overline{rg}_x)(rg(y_i)-\overline{rg}_y)} {\sqrt{\sum_{i}(rg(x_i)-\overline{rg}_x) ^2}\sqrt{\sum_{i}(rg(y_i)-\overline{rg}_y)^2}}\\
	&= \frac { \frac{1}{n} \sum_{i}(rg(x_{i})  rg(y_{i})) - \overline{rg_x rg_y}  }{s_{rg_x} s_{rg_y}} \\
	&= \frac {{Cov}(rg_{x},rg_{y} )} { s_{rg_x} s_{rg_y} }
\end{align}
Somit lassen sich auch nicht-lineare Korrelationen in Datensätzen erkennen.
Insbesondere im Betrachtung des exponentiellem Verhaltens in Abhängigkeit von der Temperatur ist diese Art der Korrelation wichtig.
Zur Berechnung des Anteils an der \it{erklärten} Varianz in linearen Modellen allerdings kann diese Variante nicht verwendet werden.
Hier wird ebenfalls ein lineares Korrelationsmaß benötigt.

\subsubsection{Informationskriterien}

Je mehr Variablen für ein Modell in Betracht gezogen werden, um so komplexer wird es. Meist wünscht man sich aber ein einfaches Modell, dass mit möglichst wenigen Variablen sehr gute Vorhersagen treffen kann. Mit verschiedenen Informationskriterien kann man nach Variablen mit der minimale Varianz der Residuen suchen. Das \emph{Bayessches Informationskriterium (BIC)}\footnotetext[1]{Schwarz-Bayes Criterion (SBC))} ist im Vergleich zu \emph{Akaikes Informationskriterium} abhängig von der Stichprobengröße.

$$\displaystyle AIC_{\ell }=-2\ell (\mathbf {\hat {\theta }} )+2k$$

$$\displaystyle BIC_{\ell }=-2\ell (\mathbf {\hat {\theta }} )+\log(n)k$$

Dies machen wir uns bei unseren Testdaten nützlich, da unsere Stichprobe recht klein ist. Zusätzlich betrachten wir noch das \emph{korrigierte Bestimmtheitsmaß  $\bar{R^2}$ (adjr2; engl. \it{adjusted r-squared})}. Es ist im Vergleich zum Bestimmtheitsmaß $R^2$ angepasst an die Anzahl der Variablen im Modell. Es steigt nur an, wenn die Variable das Modell stärker verbessert als der Zufall, ansonsten sinkt es.

$$\bar R^2 = 1- (1-R^2) \frac{n-1}{n-p-1} = R^2 - (1-R^2) \frac{p}{n-p-1}$$

\subsubsection{Test auf Vorliegen einer Normalverteilung}

Der \emph{Shapiro-Wilk-Test} ist ein statistischer Test zur Überprüfung der Hypothese, ob Variablen normalverteilt sind. Wenn bei dem Test der p-Value großer als 0.05 ist, dann ist die Variable normalverteilt.
Dieser Test ist anwendbar, wenn die Anzahl der Variablen zwischen 3 und 5000 liegt.
Somit ist es geeignet für unsere Variablen. Der Test basiert auf der Teststatistik W, der den graphischen Überprüfungen (zum Beispiel QQ-Plot) einen Wert zuweist \cite{2012shapiro}:

$$\textit{W} = {{b^2}\over {(n-1)s^2}}$$


\noindent mit $b^2$ als quadrierte Steigung der Regressionsgeraden im QQ-Plot.


\subsubsection{F-Test in geschachtelten Modellen}
Der \it{F-Test} überprüft, ob zwei verschachtelte Modelle mit den Featuremengen $M_1 \subseteq M_2$ sich signifikant unterscheiden.
Hierbei wird auf den gleichen Daten evaluiert.
Unter Annahme der Nullhypothese ist die Test-Statistik F-verteilt und abhängig von den Freiheitsgraden (Anzahl der Features im Modell).
Mit der Nullhypothese wird überprüft, ob die hinzugefügten Features des erweiterten Modells statistisch irrelevant sind ($H_0: \beta_i = 0$).

Die F-Statistik wird gebildet durch:
\begin{equation}
	F=\frac{\frac{RSS_1-RSS_2}{p_2-p_1}}{\frac{RSS_2}{n-p_2}}
\end{equation}
mit den quadrierten Residuen $RSS$, den Freiheitsgraden $p_i$ in den Modellen $M_i$ und das um weitere Feature erweiterte Modell $M_2$.
Ist der F-Wert je nach Signifikanzniveau hinreichend groß, kann die Nullhypothese abgelehnt werden:
Das erweiterte Modell beschreibt die Daten nun signifikant genauer.
Der Fehler $RSS$ wird so stark verringert, dass es auch eine Erhöhung der Freiheitsgrade rechtfertigt. 
\\
Die R-Funktion \lstinline|anova(model1, model2)| führt derartige Tests durch.
Ist der p-Value (in R \lstinline|F Pr(>F)|) kleiner als das Signifikanzniveau, so wird im Rahmen der Variablenselektion das erweiterte Modell favorisiert.
