\section{Einleitung}
\label{sec-intro}

\subsection{Bodenatmung als geophysikalischer Prozess}
\cite{foo}

\subsection{Statistische Grundlagen}

\subsubsection{Fehlermaße}
RSS (\it{Residual sum of Suqres}).
SPSE ist der summierte quadratische Fehler zwischen Modellvorhersage und Messwert auf unabhängigen Testdaten:
\begin{equation}
	\widehat{SPSE} = \sum_{i=1}^n (y_i - \vec{\beta} * x_i^T )^2
\end{equation}
Das Modell wurde vorher mit anderen Trainingsdaten erstellt.

\subsubsection{Korrelation}
Unter \it{Korrelation} versteht man die „Wechselbeziehung“ zweier Zufallsgrößen.
Dieser Zusammenhang kann entweder \it{linear} (Korrelationskoeffizient nach Pearson) oder lediglich \it{monoton} sein.
Ist eine Korrelation nicht gegeben, so scheint die Zufallsgröße als ungeeigneter Prädiktor für die jeweils andere Variabel.
Kausale Beziehungen erfordern Korrelation.
\\
Der \it{lineare, empirische Korrelationskoeffizient nach Person} zwischen den Variabeln $X$ und $Y$ wird definiert durch:
\begin{equation}
	Kor_e(x,y) := \varrho_e(x,y) := r_{xy} := \frac{
		\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)
	}{
	\sqrt{
		\sum_{i=1}^n(x_i-\bar x)^2\cdot
		\sum_{i=1}^n(y_i-\bar y)^2
	}
	}
\end{equation}
mit den empirischen Mittelwert $\bar x$ aus $n$ Messwerten von $X$.
Möchte man lediglich ein \it{lineares} Modell erstellen, so ist die Pearson-Korrelation zu wählen.
\\
Eine allgemeinere Beschreibung der Korrelation ist die nach \it{Spearsman}, welche auf Ranglisten beruht:\\
\begin{align}
	r_s &= \frac{\sum_{i}(rg(x_i)-\overline{rg}_x)(rg(y_i)-\overline{rg}_y)} {\sqrt{\sum_{i}(rg(x_i)-\overline{rg}_x) ^2}\sqrt{\sum_{i}(rg(y_i)-\overline{rg}_y)^2}}\\
	&= \frac { \frac{1}{n} \sum_{i}(rg(x_{i})  rg(y_{i})) - \overline{rg_x rg_y}  }{s_{rg_x} s_{rg_y}} \\
	&= \frac {{Cov}(rg_{x},rg_{y} )} { s_{rg_x} s_{rg_y} }
\end{align}
Somit lassen sich auch nicht-lineare Korrelationen in Datensätzen erkennen.
Insbesondere im Betrachtung des exponentiellem Verhaltens in Abhängigkeit von der Temperatur ist diese Art der Korrelation wichtig.
Zur Berechnung des Anteils an der \it{erklärten} Varianz in linearen Modellen allerdings kann diese Variante nicht verwendet werden.

\subsubsection{Informationskriterien}
BIC/AIC

\subsubsection{Test auf Vorliegen einer Normalverteilung}
Shapiro

\subsubsection{F-Test in geschachtelten Modellen}
Der \it{F-Test} überprüft, ob zwei verschachtelte Modelle mit den Featuremengen $M_1 \subseteq M_2$ sich signifikant unterscheiden.
Hierbei wird auf den gleichen Testdaten evaluiert.
Die Statistik ist F-verteilt unter Annahme der Nullhypothese und abhängig von den Freiheitsgraden (Anzahl der Features im Modell).
Es wird die Nullhypothese überprüft, ob die hinzugefügten Features des erweiterten Modells statistisch irrelevant sind ($H_0: \beta_i = 0$).
Die F-Statistik wird gebildet durch:
\begin{equation}
	F=\frac{\frac{RSS_1-RSS_2}{p_2-p_1}}{\frac{RSS_2}{n-p_2}}
\end{equation}
mit den quadrierten Residuen $RSS$, den Anzahl an Freiheitsgraden $p_i$ in den Modellen $M_1$ und das um  weitere Feature erweiterte Modell $M_2$.
Ist der F-Wert je nach Signifikanzniveau hinreichend groß, kann die Nullhypothese abgelehnt werden:
Das erweiterte Modell beschreibt die Daten nun signifikant genauer.
Der Fehler $RSS$ wird so stark verringert, dass es auch eine Erhöhung der Freiheitsgrade rechtfertigt. 
\\
Die R-Funktion \lstinline|anova(model1, model2)| führt derartige Tests durch. Ist der p-Value (in R \lstinline|F Pr(>F)|) kleiner als das Signifikanzniveau, so wird im Rahmen der Variabelnselektion das erweiterte Modell favorisiert.
